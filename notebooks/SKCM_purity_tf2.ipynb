{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285eb5b2",
   "metadata": {},
   "source": [
    "# P-NET Example Notebook: SKCM Tumor Purity Prediction (TensorFlow 2.x)\n",
    "\n",
    "This notebook demonstrates using P-NET for tumor purity prediction as a regression task.\n",
    "Adapted from the PyTorch implementation to use TensorFlow 2.x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86687227",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, '/procedure/pnet_prostate_paper')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240ef86",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f27be",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# GitHub data base URL\n",
    "GITHUB_DATA_BASE = \"https://raw.githubusercontent.com/vanallenlab/pnet/main/data\"\n",
    "\n",
    "# Model configuration\n",
    "config = {\n",
    "    'n_hidden_layers': 2,\n",
    "    'activation': 'relu',\n",
    "    'dropout': 0.3,\n",
    "    'w_reg': 0.001,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 50,\n",
    "    'batch_size': 32,\n",
    "    'use_weighted_loss': False  # Set to True to use weighted MSE\n",
    "}\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a922cf",
   "metadata": {},
   "source": [
    "## Custom Loss Function\n",
    "\n",
    "We define a weighted MSE loss that penalizes bad predictions in extreme samples more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962b78a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class WeightedMSELoss(Loss):\n",
    "    \"\"\"\n",
    "    Weighted MSE Loss that penalizes predictions more for samples \n",
    "    with extreme purity values (far from 0.5).\n",
    "    \"\"\"\n",
    "    def __init__(self, name='weighted_mse', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate the absolute distance of the true values from 0.5\n",
    "        distance_from_center = tf.abs(y_true - 0.5)\n",
    "        # Scale weights: further from 0.5 gets higher weight\n",
    "        weights = 1 + distance_from_center\n",
    "        # Calculate weighted MSE\n",
    "        squared_error = tf.square(y_true - y_pred)\n",
    "        weighted_se = weights * squared_error\n",
    "        return tf.reduce_mean(weighted_se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04c4d0",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll attempt to load SKCM data from the GitHub repository. If that fails, we'll use synthetic data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0485b0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_tcga_skcm_data():\n",
    "    \"\"\"Load SKCM RNA and CNA data.\"\"\"\n",
    "    print(\"Attempting to load SKCM data from GitHub...\")\n",
    "    \n",
    "    # Try to load from GitHub\n",
    "    try:\n",
    "        # Note: Update these URLs based on actual file structure in the repository\n",
    "        rna_url = f\"{GITHUB_DATA_BASE}/skcm_tcga_pan_can_atlas_2018/data_RNA_Seq_v2_expression_median.txt\"\n",
    "        cna_url = f\"{GITHUB_DATA_BASE}/skcm_tcga_pan_can_atlas_2018/data_CNA.txt\"\n",
    "        \n",
    "        rna = pd.read_csv(rna_url, delimiter='\\t', index_col=0)\n",
    "        rna = rna.drop(['Entrez_Gene_Id'], errors='ignore').T\n",
    "        \n",
    "        cna = pd.read_csv(cna_url, delimiter='\\t', index_col=0)\n",
    "        cna = cna.drop(['Entrez_Gene_Id'], errors='ignore').T\n",
    "        \n",
    "        print(f\"Successfully loaded data - RNA shape: {rna.shape}, CNA shape: {cna.shape}\")\n",
    "        return rna, cna\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load from GitHub: {e}\")\n",
    "        print(\"Using synthetic data for demonstration...\")\n",
    "        \n",
    "        # Create synthetic data\n",
    "        n_samples = 200\n",
    "        n_genes = 500\n",
    "        sample_ids = [f\"TCGA-SKCM-{i:04d}\" for i in range(n_samples)]\n",
    "        gene_ids = [f\"GENE{i:04d}\" for i in range(n_genes)]\n",
    "        \n",
    "        rna = pd.DataFrame(\n",
    "            np.random.randn(n_samples, n_genes) * 2,\n",
    "            index=sample_ids,\n",
    "            columns=gene_ids\n",
    "        )\n",
    "        \n",
    "        cna = pd.DataFrame(\n",
    "            np.random.choice([-2, -1, 0, 1, 2], size=(n_samples, n_genes), \n",
    "                           p=[0.05, 0.15, 0.6, 0.15, 0.05]),\n",
    "            index=sample_ids,\n",
    "            columns=gene_ids\n",
    "        )\n",
    "        \n",
    "        return rna, cna\n",
    "\n",
    "# Load the data\n",
    "rna, cna = load_tcga_skcm_data()\n",
    "print(f\"RNA shape: {rna.shape}\")\n",
    "print(f\"CNA shape: {cna.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013a494",
   "metadata": {},
   "source": [
    "## Load Tumor Purity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b3b97",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_tumor_purity_data(rna_samples):\n",
    "    \"\"\"Load or create tumor purity data.\"\"\"\n",
    "    try:\n",
    "        purity_url = f\"{GITHUB_DATA_BASE}/TCGA_mastercalls.abs_tables_JSedit.fixed.txt\"\n",
    "        purity_data = pd.read_csv(purity_url, delimiter='\\t', index_col='array')\n",
    "        \n",
    "        # Get common samples\n",
    "        common_samples = list(set(purity_data.index) & set(rna_samples))\n",
    "        if len(common_samples) > 0:\n",
    "            return purity_data.loc[common_samples, 'purity']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"Using synthetic purity data...\")\n",
    "    # Create synthetic purity values using beta distribution\n",
    "    purity = pd.Series(\n",
    "        np.random.beta(2, 2, len(rna_samples)),\n",
    "        index=rna_samples,\n",
    "        name='purity'\n",
    "    )\n",
    "    return purity\n",
    "\n",
    "purity = load_tumor_purity_data(rna.index)\n",
    "print(f\"Purity data shape: {purity.shape}\")\n",
    "print(f\"Purity range: [{purity.min():.3f}, {purity.max():.3f}]\")\n",
    "\n",
    "# Visualize purity distribution\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(purity, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Tumor Purity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Tumor Purity in SKCM Dataset')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efeb29",
   "metadata": {},
   "source": [
    "## Load Cancer Gene List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cancer_genes():\n",
    "    \"\"\"Load cancer gene list.\"\"\"\n",
    "    try:\n",
    "        genes_url = f\"{GITHUB_DATA_BASE}/../pnet_database/genes/cancer_genes.txt\"\n",
    "        genes_df = pd.read_csv(genes_url, header=None)\n",
    "        return genes_df[0].tolist()\n",
    "    except:\n",
    "        # Use a default list of well-known cancer genes\n",
    "        return ['TP53', 'EGFR', 'PTEN', 'KRAS', 'BRAF', 'PIK3CA', 'MYC', \n",
    "                'RB1', 'APC', 'VHL', 'CDKN2A', 'NRAS', 'IDH1', 'BRCA1', 'BRCA2']\n",
    "\n",
    "cancer_genes = load_cancer_genes()\n",
    "print(f\"Loaded {len(cancer_genes)} cancer genes\")\n",
    "print(f\"First 5 genes: {cancer_genes[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeca303",
   "metadata": {},
   "source": [
    "## Prepare Data for P-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9052ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common samples\n",
    "common_samples = list(set(rna.index) & set(cna.index) & set(purity.index))\n",
    "print(f\"Common samples across all data types: {len(common_samples)}\")\n",
    "\n",
    "# Subset to common samples\n",
    "rna = rna.loc[common_samples]\n",
    "cna = cna.loc[common_samples]\n",
    "purity = purity.loc[common_samples]\n",
    "\n",
    "# Find available cancer genes in the data\n",
    "available_genes = list(set(cancer_genes) & set(rna.columns) & set(cna.columns))\n",
    "print(f\"Available cancer genes in data: {len(available_genes)}\")\n",
    "\n",
    "# If too few cancer genes, use top variable genes\n",
    "if len(available_genes) < 50:\n",
    "    print(\"Using top variable genes instead...\")\n",
    "    rna_var = rna.var()\n",
    "    top_genes = rna_var.nlargest(min(300, len(rna_var))).index.tolist()\n",
    "    available_genes = list(set(top_genes) & set(cna.columns))\n",
    "    print(f\"Selected {len(available_genes)} genes based on variance\")\n",
    "\n",
    "# Subset to selected genes\n",
    "rna_subset = rna[available_genes]\n",
    "cna_subset = cna[available_genes]\n",
    "\n",
    "# Create combined feature matrix\n",
    "genetic_data = pd.concat([rna_subset, cna_subset], axis=1, keys=['rna', 'cna'])\n",
    "print(f\"Combined feature matrix shape: {genetic_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883d057",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf544a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(common_samples)), \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=(purity > purity.median()).astype(int)\n",
    ")\n",
    "\n",
    "# Prepare data arrays\n",
    "x_train = genetic_data.iloc[train_idx].values.astype(np.float32)\n",
    "x_test = genetic_data.iloc[test_idx].values.astype(np.float32)\n",
    "y_train = purity.iloc[train_idx].values.reshape(-1, 1).astype(np.float32)\n",
    "y_test = purity.iloc[test_idx].values.reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "print(f\"Training set: {x_train.shape}, Test set: {x_test.shape}\")\n",
    "print(f\"Y train range: [{y_train.min():.3f}, {y_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7c913",
   "metadata": {},
   "source": [
    "## Build P-NET Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pnet_regression_model(n_features, n_genes, config):\n",
    "    \"\"\"Build P-NET model for regression.\"\"\"\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(n_features,), name='genetic_features')\n",
    "    \n",
    "    # Gene layer - reduce features to genes\n",
    "    x = tf.keras.layers.Dense(\n",
    "        n_genes, \n",
    "        activation=config['activation'],\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(config['w_reg']),\n",
    "        name='gene_layer'\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.Dropout(config['dropout'])(x)\n",
    "    \n",
    "    # Pathway layers with progressive reduction\n",
    "    layer_sizes = [n_genes]\n",
    "    for i in range(config['n_hidden_layers']):\n",
    "        n_units = max(10, layer_sizes[-1] // 2)\n",
    "        layer_sizes.append(n_units)\n",
    "        \n",
    "        x = tf.keras.layers.Dense(\n",
    "            n_units,\n",
    "            activation=config['activation'],\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(config['w_reg']),\n",
    "            name=f'pathway_layer_{i+1}'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.Dropout(config['dropout'])(x)\n",
    "    \n",
    "    # Output layer for regression (no activation)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear', name='purity_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='PNET_Regression')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_pnet_regression_model(x_train.shape[1], len(available_genes), config)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=config['learning_rate'])\n",
    "if config['use_weighted_loss']:\n",
    "    loss = WeightedMSELoss()\n",
    "else:\n",
    "    loss = 'mse'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d290331",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0652f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=config['batch_size'],\n",
    "    epochs=config['epochs'],\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd2f0d",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History - Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Val MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Training History - MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdebf91b",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = model.predict(x_test, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "correlation, p_value = pearsonr(y_test.flatten(), y_pred.flatten())\n",
    "\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")\n",
    "print(f\"Test R²: {r2:.4f}\")\n",
    "print(f\"Pearson correlation: {correlation:.4f} (p={p_value:.4e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937a17d",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "df_results = pd.DataFrame({\n",
    "    'True Purity': y_test.flatten(),\n",
    "    'Predicted Purity': y_pred.flatten()\n",
    "})\n",
    "\n",
    "# Regression plot\n",
    "sns.regplot(data=df_results, x='True Purity', y='Predicted Purity', \n",
    "            color='#41B6E6', scatter_kws={'alpha':0.6})\n",
    "\n",
    "# Add diagonal line\n",
    "plt.plot([0, 1], [0, 1], color='#FFA300', linestyle='--', \n",
    "         label='Perfect prediction', linewidth=2)\n",
    "\n",
    "# Add metrics text\n",
    "plt.text(0.05, 0.95, \n",
    "         f'Correlation: {correlation:.3f}\\nR²: {r2:.3f}\\nMSE: {mse:.3f}', \n",
    "         transform=plt.gca().transAxes,\n",
    "         verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.xlabel('True Tumor Purity')\n",
    "plt.ylabel('Predicted Tumor Purity')\n",
    "plt.title('SKCM Tumor Purity Prediction')\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbc482",
   "metadata": {},
   "source": [
    "## Analyze Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca110b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors\n",
    "errors = y_test.flatten() - y_pred.flatten()\n",
    "abs_errors = np.abs(errors)\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error (True - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, abs_errors, alpha=0.6)\n",
    "plt.xlabel('True Tumor Purity')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Absolute Error vs True Purity')\n",
    "# Add trend line\n",
    "z = np.polyfit(y_test.flatten(), abs_errors, 2)\n",
    "p = np.poly1d(z)\n",
    "x_trend = np.linspace(0, 1, 100)\n",
    "plt.plot(x_trend, p(x_trend), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100149fe",
   "metadata": {},
   "source": [
    "## Train with Weighted Loss\n",
    "\n",
    "Let's retrain the model with weighted MSE loss to see if it improves predictions for extreme purity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild model with weighted loss\n",
    "config['use_weighted_loss'] = True\n",
    "\n",
    "model_weighted = build_pnet_regression_model(x_train.shape[1], len(available_genes), config)\n",
    "\n",
    "model_weighted.compile(\n",
    "    optimizer=Adam(learning_rate=config['learning_rate']),\n",
    "    loss=WeightedMSELoss(),\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "print(\"Training model with weighted loss...\")\n",
    "history_weighted = model_weighted.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=config['batch_size'],\n",
    "    epochs=config['epochs'],\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get predictions with weighted model\n",
    "y_pred_weighted = model_weighted.predict(x_test, verbose=0)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_weighted = mean_squared_error(y_test, y_pred_weighted)\n",
    "r2_weighted = r2_score(y_test, y_pred_weighted)\n",
    "corr_weighted, _ = pearsonr(y_test.flatten(), y_pred_weighted.flatten())\n",
    "\n",
    "print(f\"\\nWeighted Loss Model Results:\")\n",
    "print(f\"Test MSE: {mse_weighted:.4f} (vs {mse:.4f} standard)\")\n",
    "print(f\"Test R²: {r2_weighted:.4f} (vs {r2:.4f} standard)\")\n",
    "print(f\"Correlation: {corr_weighted:.4f} (vs {correlation:.4f} standard)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff08db",
   "metadata": {},
   "source": [
    "## Compare Standard vs Weighted Loss Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Standard MSE\n",
    "ax1 = axes[0]\n",
    "df1 = pd.DataFrame({\n",
    "    'True': y_test.flatten(),\n",
    "    'Predicted': y_pred.flatten()\n",
    "})\n",
    "sns.regplot(data=df1, x='True', y='Predicted', ax=ax1, \n",
    "            color='#41B6E6', scatter_kws={'alpha':0.6})\n",
    "ax1.plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "ax1.set_title(f'Standard MSE Loss\\nR² = {r2:.3f}')\n",
    "ax1.set_xlabel('True Purity')\n",
    "ax1.set_ylabel('Predicted Purity')\n",
    "\n",
    "# Weighted MSE\n",
    "ax2 = axes[1]\n",
    "df2 = pd.DataFrame({\n",
    "    'True': y_test.flatten(),\n",
    "    'Predicted': y_pred_weighted.flatten()\n",
    "})\n",
    "sns.regplot(data=df2, x='True', y='Predicted', ax=ax2,\n",
    "            color='#FF6B6B', scatter_kws={'alpha':0.6})\n",
    "ax2.plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
    "ax2.set_title(f'Weighted MSE Loss\\nR² = {r2_weighted:.3f}')\n",
    "ax2.set_xlabel('True Purity')\n",
    "ax2.set_ylabel('Predicted Purity')\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe385fa",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis (Simplified)\n",
    "\n",
    "Since we built a custom model, we can examine the weights of the gene layer to identify important genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89183dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gene layer weights\n",
    "gene_layer = model.get_layer('gene_layer')\n",
    "gene_weights = gene_layer.get_weights()[0]  # Shape: (n_features, n_genes)\n",
    "\n",
    "# Calculate importance as mean absolute weight per gene\n",
    "# Split weights for RNA and CNA\n",
    "n_genes = len(available_genes)\n",
    "rna_weights = gene_weights[:n_genes, :]\n",
    "cna_weights = gene_weights[n_genes:, :]\n",
    "\n",
    "# Calculate importance scores\n",
    "rna_importance = np.mean(np.abs(rna_weights), axis=0)\n",
    "cna_importance = np.mean(np.abs(cna_weights), axis=0)\n",
    "total_importance = rna_importance + cna_importance\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Gene': available_genes,\n",
    "    'RNA_Importance': rna_importance,\n",
    "    'CNA_Importance': cna_importance,\n",
    "    'Total_Importance': total_importance\n",
    "}).sort_values('Total_Importance', ascending=False)\n",
    "\n",
    "# Plot top important genes\n",
    "top_n = 20\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "top_genes = importance_df.head(top_n)\n",
    "x = np.arange(top_n)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, top_genes['RNA_Importance'], width, label='RNA', alpha=0.8)\n",
    "plt.bar(x + width/2, top_genes['CNA_Importance'], width, label='CNA', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Genes')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title(f'Top {top_n} Most Important Genes for Tumor Purity Prediction')\n",
    "plt.xticks(x, top_genes['Gene'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most important genes:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07332d",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Using P-NET architecture for regression tasks (tumor purity prediction)\n",
    "2. Loading data from remote sources (GitHub)\n",
    "3. Implementing custom loss functions (Weighted MSE)\n",
    "4. Comparing different loss functions for improved performance\n",
    "5. Basic feature importance analysis\n",
    "\n",
    "The weighted MSE loss can help improve predictions for samples with extreme purity values by giving them more weight during training."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
