{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328572a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SKCM Tumor Purity Prediction with P-NET - TensorFlow 2.x Adaptation\n",
    "Adapted from PyTorch implementation to use TensorFlow 2.x with the prostate cancer project infrastructure.\n",
    "This script demonstrates tumor purity prediction as a regression task.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b859baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the project root is in Python path\n",
    "sys.path.insert(0, '/procedure/pnet_prostate_paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 2.x imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98ff60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Project-specific imports\n",
    "from data.data_access import Data\n",
    "from model.builders.prostate_models import build_pnet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub raw content base URL for data\n",
    "GITHUB_DATA_BASE = \"https://raw.githubusercontent.com/vanallenlab/pnet/main/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5813af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_level='INFO'):\n",
    "    \"\"\"Configure logging for the script.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, log_level.upper()),\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(),\n",
    "            logging.FileHandler('/procedure/pnet_prostate_paper/results/skcm_purity_training.log')\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    logging.info(f'Random seeds set to {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedMSELoss(Loss):\n",
    "    \"\"\"\n",
    "    TensorFlow 2.x implementation of Weighted MSE Loss.\n",
    "    Penalizes predictions more for samples with extreme purity values (far from 0.5).\n",
    "    \"\"\"\n",
    "    def __init__(self, name='weighted_mse', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate the absolute distance of the true values from 0.5\n",
    "        distance_from_center = tf.abs(y_true - 0.5)\n",
    "        # Scale weights as needed; further from 0.5 gets higher weight\n",
    "        weights = 1 + distance_from_center\n",
    "        # Calculate weighted MSE\n",
    "        squared_error = tf.square(y_true - y_pred)\n",
    "        weighted_se = weights * squared_error\n",
    "        return tf.reduce_mean(weighted_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e79a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tcga_skcm_data():\n",
    "    \"\"\"\n",
    "    Load SKCM data from GitHub repository.\n",
    "    Returns RNA and CNA data as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    logging.info(\"Loading SKCM data from GitHub...\")\n",
    "    \n",
    "    # Construct URLs for SKCM data\n",
    "    # Note: These are example paths - actual paths in the GitHub repo might differ\n",
    "    rna_url = f\"{GITHUB_DATA_BASE}/skcm_tcga_pan_can_atlas_2018/data_RNA_Seq_v2_expression_median.txt\"\n",
    "    cna_url = f\"{GITHUB_DATA_BASE}/skcm_tcga_pan_can_atlas_2018/data_CNA.txt\"\n",
    "    \n",
    "    try:\n",
    "        # Load RNA data\n",
    "        logging.info(f\"Loading RNA data from: {rna_url}\")\n",
    "        rna = pd.read_csv(rna_url, delimiter='\\t', index_col=0)\n",
    "        rna = rna.drop(['Entrez_Gene_Id'], errors='ignore').T\n",
    "        \n",
    "        # Load CNA data\n",
    "        logging.info(f\"Loading CNA data from: {cna_url}\")\n",
    "        cna = pd.read_csv(cna_url, delimiter='\\t', index_col=0)\n",
    "        cna = cna.drop(['Entrez_Gene_Id'], errors='ignore').T\n",
    "        \n",
    "        logging.info(f\"RNA data shape: {rna.shape}, CNA data shape: {cna.shape}\")\n",
    "        return rna, cna\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load SKCM data: {e}\")\n",
    "        # Return synthetic data for demonstration if real data fails\n",
    "        logging.warning(\"Using synthetic SKCM data for demonstration...\")\n",
    "        return create_synthetic_skcm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_skcm_data(n_samples=200, n_genes=500):\n",
    "    \"\"\"Create synthetic SKCM data for demonstration if real data is unavailable.\"\"\"\n",
    "    # Create sample IDs\n",
    "    sample_ids = [f\"TCGA-SKCM-{i:04d}\" for i in range(n_samples)]\n",
    "    gene_ids = [f\"GENE{i:04d}\" for i in range(n_genes)]\n",
    "    \n",
    "    # Synthetic RNA expression data (normalized log2 values)\n",
    "    rna = pd.DataFrame(\n",
    "        np.random.randn(n_samples, n_genes) * 2,\n",
    "        index=sample_ids,\n",
    "        columns=gene_ids\n",
    "    )\n",
    "    \n",
    "    # Synthetic CNA data (-2, -1, 0, 1, 2)\n",
    "    cna = pd.DataFrame(\n",
    "        np.random.choice([-2, -1, 0, 1, 2], size=(n_samples, n_genes), p=[0.05, 0.15, 0.6, 0.15, 0.05]),\n",
    "        index=sample_ids,\n",
    "        columns=gene_ids\n",
    "    )\n",
    "    \n",
    "    return rna, cna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0da2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tumor_purity_data():\n",
    "    \"\"\"Load tumor purity data from GitHub or create synthetic.\"\"\"\n",
    "    logging.info(\"Loading tumor purity data...\")\n",
    "    \n",
    "    purity_url = f\"{GITHUB_DATA_BASE}/TCGA_mastercalls.abs_tables_JSedit.fixed.txt\"\n",
    "    \n",
    "    try:\n",
    "        purity_data = pd.read_csv(purity_url, delimiter='\\t', index_col='array')\n",
    "        return purity_data['purity']\n",
    "    except:\n",
    "        logging.warning(\"Using synthetic purity data...\")\n",
    "        # Create synthetic purity values (0-1)\n",
    "        n_samples = 200\n",
    "        sample_ids = [f\"TCGA-SKCM-{i:04d}\" for i in range(n_samples)]\n",
    "        purity = pd.Series(\n",
    "            np.random.beta(2, 2, n_samples),  # Beta distribution gives values between 0-1\n",
    "            index=sample_ids,\n",
    "            name='purity'\n",
    "        )\n",
    "        return purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e557f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cancer_genes():\n",
    "    \"\"\"Load cancer gene list from GitHub or use default list.\"\"\"\n",
    "    logging.info(\"Loading cancer gene list...\")\n",
    "    \n",
    "    genes_url = f\"{GITHUB_DATA_BASE}/../pnet_database/genes/cancer_genes.txt\"\n",
    "    \n",
    "    try:\n",
    "        genes_df = pd.read_csv(genes_url, header=None)\n",
    "        cancer_genes = genes_df[0].tolist()\n",
    "        logging.info(f\"Loaded {len(cancer_genes)} cancer genes\")\n",
    "        return cancer_genes\n",
    "    except:\n",
    "        logging.warning(\"Using default cancer gene list...\")\n",
    "        # Use a small default list\n",
    "        return ['TP53', 'EGFR', 'PTEN', 'KRAS', 'BRAF', 'PIK3CA', 'MYC', 'RB1', 'APC', 'VHL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b2e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_skcm_data_for_pnet(rna, cna, purity, cancer_genes, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Prepare SKCM data in the format expected by our P-NET implementation.\n",
    "    \"\"\"\n",
    "    # Find common samples\n",
    "    common_samples = list(set(rna.index) & set(cna.index) & set(purity.index))\n",
    "    logging.info(f\"Found {len(common_samples)} common samples across all data types\")\n",
    "    \n",
    "    # Subset to common samples\n",
    "    rna = rna.loc[common_samples]\n",
    "    cna = cna.loc[common_samples]\n",
    "    purity = purity.loc[common_samples]\n",
    "    \n",
    "    # Find available cancer genes\n",
    "    available_genes = list(set(cancer_genes) & set(rna.columns) & set(cna.columns))\n",
    "    if len(available_genes) < len(cancer_genes):\n",
    "        logging.warning(f\"Only {len(available_genes)} of {len(cancer_genes)} cancer genes found in data\")\n",
    "    \n",
    "    # If too few genes, use top variable genes\n",
    "    if len(available_genes) < 50:\n",
    "        logging.info(\"Using top variable genes instead of cancer genes\")\n",
    "        rna_var = rna.var()\n",
    "        top_genes = rna_var.nlargest(min(500, len(rna_var))).index.tolist()\n",
    "        available_genes = list(set(top_genes) & set(cna.columns))\n",
    "    \n",
    "    # Subset to available genes\n",
    "    rna = rna[available_genes]\n",
    "    cna = cna[available_genes]\n",
    "    \n",
    "    # Create combined feature matrix (concatenate RNA and CNA)\n",
    "    # This mimics the multi-modal input structure\n",
    "    combined_features = pd.concat([rna, cna], axis=1, keys=['rna', 'cna'])\n",
    "    \n",
    "    # Split data\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        range(len(common_samples)), \n",
    "        test_size=test_size, \n",
    "        random_state=42,\n",
    "        stratify=(purity > purity.median()).astype(int)  # Stratify by high/low purity\n",
    "    )\n",
    "    \n",
    "    x_train = combined_features.iloc[train_idx].values\n",
    "    x_test = combined_features.iloc[test_idx].values\n",
    "    y_train = purity.iloc[train_idx].values.reshape(-1, 1)\n",
    "    y_test = purity.iloc[test_idx].values.reshape(-1, 1)\n",
    "    \n",
    "    # Sample info\n",
    "    info_train = np.array(combined_features.index[train_idx])\n",
    "    info_test = np.array(combined_features.index[test_idx])\n",
    "    \n",
    "    # Column info\n",
    "    columns = combined_features.columns\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, info_train, info_test, columns, available_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83601c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skcm_model(n_features, n_genes, config):\n",
    "    \"\"\"\n",
    "    Create P-NET model for SKCM tumor purity prediction (regression task).\n",
    "    \"\"\"\n",
    "    logging.info('Building P-NET model for regression...')\n",
    "    \n",
    "    # For regression, we need to modify the model configuration\n",
    "    model_params = config['model_params'].copy()\n",
    "    model_params['loss'] = 'mse'  # Use MSE for regression\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = Adam(learning_rate=model_params['learning_rate'])\n",
    "    \n",
    "    # Build a simplified model for regression\n",
    "    # Note: This is a simplified approach since build_pnet2 expects classification\n",
    "    # In practice, you might need a specialized regression version of P-NET\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(n_features,))\n",
    "    \n",
    "    # Gene layer (reduce features to genes)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        n_genes, \n",
    "        activation=model_params['activation'],\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(model_params['w_reg']),\n",
    "        name='gene_layer'\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.Dropout(model_params['dropout'])(x)\n",
    "    \n",
    "    # Pathway layers\n",
    "    for i in range(model_params['n_hidden_layers']):\n",
    "        n_units = max(10, n_genes // (2 ** (i + 1)))  # Progressively smaller layers\n",
    "        x = tf.keras.layers.Dense(\n",
    "            n_units,\n",
    "            activation=model_params['activation'],\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(model_params['w_reg']),\n",
    "            name=f'pathway_layer_{i}'\n",
    "        )(x)\n",
    "        x = tf.keras.layers.Dropout(model_params['dropout'])(x)\n",
    "    \n",
    "    # Output layer for regression\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear', name='purity_output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile with appropriate loss for regression\n",
    "    if config['training_params'].get('use_weighted_loss', False):\n",
    "        loss = WeightedMSELoss()\n",
    "    else:\n",
    "        loss = 'mse'\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    logging.info(f'Model created with {model.count_params()} parameters')\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75524a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(model, x_test, y_test, save_path=None):\n",
    "    \"\"\"\n",
    "    Evaluate regression model and create visualization.\n",
    "    \"\"\"\n",
    "    logging.info('Evaluating regression model...')\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(x_test, verbose=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    correlation, p_value = pearsonr(y_test.flatten(), y_pred.flatten())\n",
    "    \n",
    "    logging.info(f'Test MSE: {mse:.4f}')\n",
    "    logging.info(f'Test R²: {r2:.4f}')\n",
    "    logging.info(f'Pearson correlation: {correlation:.4f} (p={p_value:.4e})')\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    df = pd.DataFrame({\n",
    "        'y_test': y_test.flatten(),\n",
    "        'y_pred': y_pred.flatten()\n",
    "    })\n",
    "    \n",
    "    # Regression plot\n",
    "    sns.regplot(data=df, x='y_test', y='y_pred', color='#41B6E6', scatter_kws={'alpha':0.6})\n",
    "    \n",
    "    # Add diagonal line\n",
    "    plt.plot([0, 1], [0, 1], color='#FFA300', linestyle='--', label='Perfect prediction')\n",
    "    \n",
    "    # Add correlation text\n",
    "    plt.text(0.95, 0.05, f'Correlation: {correlation:.2f}\\nR²: {r2:.2f}', \n",
    "             ha='right', va='bottom', transform=plt.gca().transAxes,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.xlabel('True Tumor Purity')\n",
    "    plt.ylabel('Predicted Tumor Purity')\n",
    "    plt.title('SKCM Tumor Purity Prediction')\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.legend()\n",
    "    sns.despine()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        logging.info(f'Regression plot saved to {save_path}')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'correlation': correlation,\n",
    "        'p_value': p_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73707c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train P-NET model for SKCM tumor purity prediction'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--config',\n",
    "        type=str,\n",
    "        default='/procedure/pnet_prostate_paper/config/skcm_purity_params.yml',\n",
    "        help='Path to configuration YAML file'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--use-weighted-loss',\n",
    "        action='store_true',\n",
    "        help='Use weighted MSE loss for extreme values'\n",
    "    )\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Setup logging\n",
    "    logger = setup_logging('INFO')\n",
    "    logger.info('Starting SKCM tumor purity prediction with P-NET')\n",
    "    \n",
    "    # Set random seeds\n",
    "    set_random_seeds(42)\n",
    "    \n",
    "    # Load configuration\n",
    "    if os.path.exists(args.config):\n",
    "        with open(args.config, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    else:\n",
    "        # Use default configuration\n",
    "        config = {\n",
    "            'model_params': {\n",
    "                'n_hidden_layers': 2,\n",
    "                'activation': 'relu',\n",
    "                'dropout': 0.3,\n",
    "                'w_reg': 0.001,\n",
    "                'learning_rate': 0.001,\n",
    "                'epochs': 50,\n",
    "                'batch_size': 32\n",
    "            },\n",
    "            'training_params': {\n",
    "                'early_stopping': True,\n",
    "                'patience': 10,\n",
    "                'save_checkpoints': True,\n",
    "                'checkpoint_dir': '/procedure/pnet_prostate_paper/checkpoints/skcm_purity/',\n",
    "                'results_dir': '/procedure/pnet_prostate_paper/results/',\n",
    "                'use_weighted_loss': args.use_weighted_loss\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(config['training_params']['checkpoint_dir'], exist_ok=True)\n",
    "    os.makedirs(config['training_params']['results_dir'], exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    rna, cna = load_tcga_skcm_data()\n",
    "    purity = load_tumor_purity_data()\n",
    "    cancer_genes = load_cancer_genes()\n",
    "    \n",
    "    # Prepare data\n",
    "    x_train, x_test, y_train, y_test, info_train, info_test, columns, genes = prepare_skcm_data_for_pnet(\n",
    "        rna, cna, purity, cancer_genes\n",
    "    )\n",
    "    \n",
    "    logger.info(f'Training samples: {len(x_train)}, Test samples: {len(x_test)}')\n",
    "    logger.info(f'Features: {x_train.shape[1]}, Genes: {len(genes)}')\n",
    "    \n",
    "    # Create model\n",
    "    model = create_skcm_model(x_train.shape[1], len(genes), config)\n",
    "    \n",
    "    # Setup callbacks\n",
    "    callbacks = []\n",
    "    if config['training_params']['early_stopping']:\n",
    "        callbacks.append(EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config['training_params']['patience'],\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ))\n",
    "    \n",
    "    if config['training_params']['save_checkpoints']:\n",
    "        checkpoint_path = os.path.join(\n",
    "            config['training_params']['checkpoint_dir'],\n",
    "            'best_model.weights.h5'\n",
    "        )\n",
    "        callbacks.append(ModelCheckpoint(\n",
    "            checkpoint_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=True,\n",
    "            verbose=1\n",
    "        ))\n",
    "    \n",
    "    # Train model\n",
    "    logger.info('Starting model training...')\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=config['model_params']['batch_size'],\n",
    "        epochs=config['model_params']['epochs'],\n",
    "        validation_data=(x_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    plot_path = os.path.join(config['training_params']['results_dir'], 'skcm_purity_regression.png')\n",
    "    eval_metrics = evaluate_regression_model(model, x_test, y_test, plot_path)\n",
    "    \n",
    "    # Save results\n",
    "    results_file = os.path.join(config['training_params']['results_dir'], 'skcm_purity_metrics.yaml')\n",
    "    with open(results_file, 'w') as f:\n",
    "        yaml.dump(eval_metrics, f)\n",
    "    \n",
    "    logger.info('Training completed successfully!')\n",
    "    logger.info(f'Final Results:')\n",
    "    for metric, value in eval_metrics.items():\n",
    "        logger.info(f'  {metric}: {value:.4f}')\n",
    "    \n",
    "    return model, eval_metrics, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model, metrics, history = main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
